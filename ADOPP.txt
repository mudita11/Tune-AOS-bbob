
# DE parameters
FF                   "--FF "                   r (0.1, 2.0)                                          # Scaling factor
CR                   "--CR "                   r (0.1, 1.0)                                          # Crossover rate
NP                   "--NP "                   i (50, 400)                                           # Population size
top_NP               "--top_NP "               r (0.02, 1.0)                                         # Top candidates
mutation             "--mutation "             c (known_aos)                                         # Mutation strategy
##### AOS:  ADOPP.txt
# Unknown_AOS
OM_choice            "--OM_choice "            c (5)                                                 # Offspring metric selected (5:improv_wrt_median)
# ProbabilityType
prob_choice          "--prob_choice "          c (0)                                                 # 0:Probability_Matching
p_min                "--p_min "                r (0.0, 1.0)                                          # Minimum probability of selection of an operator
learning_rate        "--learning_rate "        r (0.0, 1.0)                                          # Learning Rate
error_prob           "--error_prob "           r (0.0, 1.0)           | prob_choice == 0             # Probability noise
p_max                "--p_max "                r (0.0, 1.0)                                          # Maximum probability of selection of an operator
# RewardType
rew_choice           "--rew_choice "           c (5)                                                 # 5:Success_Rate
max_gen              "--max_gen "              i (1, 50)              | rew_choice == 5              # Maximum number of generations for generational window
fix_appl             "--fix_appl "             i (10, 150)                                           # Maximum number of successful operator applications for generational window
theta                "--theta "                i (36, 45, 54, 90)                                    # Search direction
window_size          "--window_size "          i (20, 150)                                           # Size of window
decay                "--decay "                r (0.0, 1.0)                                          # Decay value to emphasise the choice of better operator
succ_lin_quad        "--succ_lin_quad "        i (1, 2)               | rew_choice == 5              # Operator success as linear or quadratic
frac                 "--frac "                 r (0.0, 1.0)           | rew_choice == 5              # Fraction of sum of successes of all operators
noise                "--noise "                r (0.0, 1.0)           | rew_choice == 5              # Small noise for randomness
normal_factor        "--normal_factor "        i (0, 1)                                              # Choice to normalise
scaling_constant     "--scaling_constant "     r (0.001, 1.0)                                        # Scaling constant
alpha                "--alpha "                i (0, 1)                                              # Choice to normalise by best produced by any operator
beta                 "--beta "                 i (0, 1)                                              # Choice to include the difference between budget used by an operator in previous two generations
intensity            "--intensity "            i (1, 2, 3)                                           # Intensify the changes of best fitness value
# QualityType
qual_choice          "--qual_choice "          c (2)                                                 # 2:Quality_Identity
scaling_factor       "--scaling_factor "       r (0.01, 100)                                         # Scaling Factor
decay_rate           "--decay_rate "           r (0.0, 1.0)                                          # Decay rate
q_min                "--q_min "                r (0.0, 1.0)                                          # Minimum quality attained by an operator
weight_reward        "--weight_reward "        r (0.0, 1.0)                                          # Memory for current reward
weight_old_reward    "--weight_old_reward "    r (0.0, 1.0)                                          # Memory for previous reward
discount_rate        "--discount_rate "        r (0.01, 1.0)                                         # Discount rate
# SelectionType
select_choice        "--select_choice "        c (0)                                                 # 0:Proportional_Selection
sel_eps              "--sel_eps "              r (0.0, 1.0)                                          # Random selection with probability sel_eps
